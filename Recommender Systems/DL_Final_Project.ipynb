{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL-Final-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries & Prepare the Working Directory"
      ],
      "metadata": {
        "id": "oA1MetB43GlF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NwSra4MgFDq",
        "outputId": "ff0cd062-10c5-4bf6-d5ec-9025aced249b"
      },
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install boto3\n",
        "!pip install dgl\n",
        "!pip install dgl-cu101\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/DL-PROJECT/')\n",
        "%cd /content/drive/My\\ Drive/DL-PROJECT/\n",
        "\n",
        "\n",
        "from torch.multiprocessing import Pool, Process, set_start_method\n",
        "try:\n",
        "    set_start_method('spawn')\n",
        "except RuntimeError:\n",
        "    pass"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.20.24)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.23.24)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.24->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.24->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3) (1.15.0)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.25.11)\n",
            "Requirement already satisfied: dgl-cu101 in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/DL-PROJECT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ1lohUiu2Nt"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as torch_nn_func\n",
        "import dgl\n",
        "import dgl.nn.pytorch as dglnn\n",
        "import dgl.function as dgl_func\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from collections import defaultdict\n",
        "from typing import Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from datetime import datetime\n",
        "import textwrap\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "import pickle\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "Uzobtrqgck9E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phElQR3JsJVt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dff2a3f7-e499-4330-8921-2f6ed311e4bd"
      },
      "source": [
        "user_feat_df = pd.read_csv('data/user_feat.csv')\n",
        "interact_df = pd.read_csv('data/interact.csv')\n",
        "movie_feat_df = pd.read_csv('data/item_feat.csv')\n",
        "interact_df.sort_values(by='Timestamp')\n",
        "interact_df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6040</td>\n",
              "      <td>858</td>\n",
              "      <td>4</td>\n",
              "      <td>956703932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6040</td>\n",
              "      <td>2384</td>\n",
              "      <td>4</td>\n",
              "      <td>956703954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6040</td>\n",
              "      <td>593</td>\n",
              "      <td>5</td>\n",
              "      <td>956703954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6040</td>\n",
              "      <td>1961</td>\n",
              "      <td>4</td>\n",
              "      <td>956703977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6040</td>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>956703977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID  MovieID  Rating  Timestamp\n",
              "0    6040      858       4  956703932\n",
              "1    6040     2384       4  956703954\n",
              "2    6040      593       5  956703954\n",
              "3    6040     1961       4  956703977\n",
              "4    6040     2019       5  956703977"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train & Test Data"
      ],
      "metadata": {
        "id": "T81TYy8UdDUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.28\n",
        "split_idx = int(len(interact_df) * (1 - test_size))\n",
        "user_movie_train = interact_df[: split_idx]\n",
        "user_movie_test = interact_df[split_idx: ]"
      ],
      "metadata": {
        "id": "KG1okk1DchHI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract User Information"
      ],
      "metadata": {
        "id": "nvu40rj0d0av"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KmxGDVisYY7"
      },
      "source": [
        "user_id_type = 'UserID'\n",
        "\n",
        "user_id = pd.DataFrame(user_movie_train[user_id_type].unique(), columns=[user_id_type])\n",
        "user_id['user_new_id'] = user_id.index"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Movie Information"
      ],
      "metadata": {
        "id": "nslcgqgmfBB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_id_type = 'MovieID'\n",
        "\n",
        "train_movie = user_movie_train[movie_id_type].unique().tolist()\n",
        "all_movie = movie_feat_df[movie_id_type].unique().tolist()\n",
        "\n",
        "unseen_movie = [movie for movie in all_movie if movie not in train_movie]\n",
        "train_movie.extend(unseen_movie)  \n",
        "movie_id = pd.DataFrame(train_movie, columns=[movie_id_type])\n",
        "movie_id['movie_new_id'] = movie_id.index"
      ],
      "metadata": {
        "id": "r2sbuCXEekbz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User-Movie Data for Training"
      ],
      "metadata": {
        "id": "rpEMJ6mshAgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_movie_train = user_movie_train.merge(user_id, how='left', on=user_id_type)\n",
        "user_movie_train = user_movie_train.merge(movie_id, how='left', on=movie_id_type)\n",
        "\n",
        "user_movie_train.drop_duplicates(subset=['Rating', 'user_new_id', 'movie_new_id'], keep='last', inplace=True)\n",
        "user_movie_train.sort_values(by=['Rating', 'user_new_id', 'movie_new_id'], ignore_index=True, inplace=True) \n",
        "user_movie_train.sort_values(by='Timestamp', ignore_index=True, inplace=True)  "
      ],
      "metadata": {
        "id": "Bhn5TLKJhIt_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User-Movie Data for Testing"
      ],
      "metadata": {
        "id": "SyOTuSILjKlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_movie_test = user_movie_test.merge(user_id, how='inner', on=user_id_type)\n",
        "user_movie_test = user_movie_test.merge(movie_id, how='inner', on=movie_id_type)\n",
        "test_src = user_movie_test.user_new_id.values\n",
        "test_dst = user_movie_test.movie_new_id.values\n",
        "ground_truth_test = (test_src, test_dst)"
      ],
      "metadata": {
        "id": "keE8gPtjjNBL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Adjacency Dict\n"
      ],
      "metadata": {
        "id": "JBGroz-7feu2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTGiP1ugsNJ1"
      },
      "source": [
        "adjacency_dict = {}\n",
        "\n",
        "adjacency_dict['user_movie_rating'] = user_movie_train.Rating.values\n",
        "adjacency_dict['user_movie_src'] = user_movie_train.user_new_id.values\n",
        "adjacency_dict['user_movie_dst'] = user_movie_train.movie_new_id.values"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Graph Schema based on Adjacency Dict"
      ],
      "metadata": {
        "id": "YrdCzK_kiwIV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZl5s8VtsfZo"
      },
      "source": [
        "graph_schema = {('user', 'buys', 'movie'): list(zip(adjacency_dict['user_movie_src'], adjacency_dict['user_movie_dst'])),\n",
        "                ('movie', 'watched-by', 'user'): list(zip(adjacency_dict['user_movie_dst'], adjacency_dict['user_movie_src']))\n",
        "               }"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Heterogeneous graph"
      ],
      "metadata": {
        "id": "AJHQNaA_khtk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpCCCsBnslnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a635e7-6fb8-4cc5-cc6f-5a360a5dc818"
      },
      "source": [
        "hetero_graph = dgl.heterograph(graph_schema)\n",
        "print('Graph --> \\n', hetero_graph) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph --> \n",
            " Graph(num_nodes={'movie': 3646, 'user': 4971},\n",
            "      num_edges={('movie', 'watched-by', 'user'): 720150, ('user', 'buys', 'movie'): 720150},\n",
            "      metagraph=[('movie', 'user', 'watched-by'), ('user', 'movie', 'buys')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create User Features"
      ],
      "metadata": {
        "id": "Aknhoqo_kpT6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78co_AJr7TDm"
      },
      "source": [
        "user_feat_df = user_feat_df.merge(user_id, how='inner', on=user_id_type)\n",
        "ids = user_feat_df.user_new_id.values.astype(int)\n",
        "feats = np.stack((user_feat_df.F.values, user_feat_df.M.values), axis=1)\n",
        "\n",
        "user_feat = np.zeros((hetero_graph.number_of_nodes('user'), 2))\n",
        "user_feat[ids] = feats\n",
        "\n",
        "user_feat = torch.tensor(user_feat).float()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Movie Features"
      ],
      "metadata": {
        "id": "sbK6oR42k_YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_feat_df = movie_feat_df.merge(movie_id, how='left', on=movie_id_type)\n",
        "movie_feat_df = movie_feat_df[movie_feat_df.movie_new_id < hetero_graph.number_of_nodes('movie')]  \n",
        "\n",
        "ids = movie_feat_df.movie_new_id.values.astype(int)\n",
        "\n",
        "feats = np.stack((movie_feat_df.Action.values,\n",
        "                  movie_feat_df.Animation.values,\n",
        "                  movie_feat_df.Childrens.values,\n",
        "                  movie_feat_df.Comedy.values,\n",
        "                  movie_feat_df.Crime.values,\n",
        "                  movie_feat_df.Documentary.values,\n",
        "                  movie_feat_df.Drama.values,\n",
        "                  movie_feat_df.Fantasy.values,\n",
        "                  movie_feat_df.Film_Noir.values,\n",
        "                  movie_feat_df.Horror.values,\n",
        "                  movie_feat_df.Musical.values,\n",
        "                  movie_feat_df.Mystery.values,\n",
        "                  movie_feat_df.Romance.values,\n",
        "                  movie_feat_df.Sci_Fi.values,\n",
        "                  movie_feat_df.Thriller.values,\n",
        "                  movie_feat_df.War.values,\n",
        "                  movie_feat_df.Western.values,\n",
        "                  ),\n",
        "                 axis=1)\n",
        "\n",
        "movie_feat = np.zeros((hetero_graph.number_of_nodes('movie'), feats.shape[1]))\n",
        "movie_feat[ids] = feats\n",
        "movie_feat = torch.tensor(movie_feat).float()"
      ],
      "metadata": {
        "id": "Lm-MvsX3lDMB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Features Dict from Users and Movies Features"
      ],
      "metadata": {
        "id": "9RwqCLG2lS3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_dict = {}\n",
        "features_dict['user_feat'] = user_feat\n",
        "features_dict['movie_feat'] = movie_feat"
      ],
      "metadata": {
        "id": "Z_ubgE56lXQp"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign Features to Nodes and Edges"
      ],
      "metadata": {
        "id": "oC0PVo3Smbwi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKRx2pMaWXXD"
      },
      "source": [
        "hetero_graph.nodes['user'].data['features'] = features_dict['user_feat']\n",
        "hetero_graph.nodes['movie'].data['features'] = features_dict['movie_feat']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign Features to Edges"
      ],
      "metadata": {
        "id": "jprBp4_qmlHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hetero_graph.edges['buys'].data['rating'] = torch.tensor(adjacency_dict['user_movie_rating'])\n",
        "hetero_graph.edges['watched-by'].data['rating'] = torch.tensor(adjacency_dict['user_movie_rating'])"
      ],
      "metadata": {
        "id": "MJEsceFRmyAl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Embeddings\n",
        "\n",
        "* We calculate Node embeddings to represent nodes as vectors an capture the topology of the network\n",
        "* The embeddings --> based on similarity.\n",
        "* We will use the embeddings for prediction tasks."
      ],
      "metadata": {
        "id": "iwMpISuJonLT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D51TSxay63lD"
      },
      "source": [
        "class NodeEmbedding(nn.Module):\n",
        "    def __init__(self, input_features, output_features,):\n",
        "        super().__init__()\n",
        "        self.project_features = nn.Linear(input_features, output_features)\n",
        "\n",
        "    def forward(self, node_features):\n",
        "        return self.project_features(node_features)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message passing layer"
      ],
      "metadata": {
        "id": "zICu9p7NqX_3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBf_17YCeULF"
      },
      "source": [
        "class MessagePassing(nn.Module):\n",
        "    \n",
        "      def __init__(self, input_features, output_features, dropout,):\n",
        "        super().__init__()\n",
        "        self._in_neigh_feats, self._in_self_feats = input_features\n",
        "        self._output_features = output_features \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_self = nn.Linear(self._in_self_feats, output_features, bias=False)\n",
        "        self.fc_neighbour = nn.Linear(self._in_neigh_feats, output_features, bias=False)\n",
        "        self.fc_pre_agg = nn.Linear(self._in_neigh_feats, self._in_neigh_feats, bias=False)\n",
        "      \n",
        "      def forward(self, graph, x):\n",
        "        \n",
        "        h_neighbour, h_self = x\n",
        "        h_self = self.dropout(h_self)\n",
        "        h_neighbour = self.dropout(h_neighbour)\n",
        "        \n",
        "\n",
        "        graph.srcdata['h'] = torch_nn_func.relu(self.fc_pre_agg(h_neighbour))\n",
        "        graph.update_all(dgl_func.copy_src('h', 'm'), dgl_func.mean('m', 'neigh'))\n",
        "        h_neighbour = graph.dstdata['neigh']\n",
        "\n",
        "        #message passing\n",
        "        z = self.fc_self(h_self) + self.fc_neighbour(h_neighbour)\n",
        "        z = torch_nn_func.relu(z)\n",
        "\n",
        "        z_normalization = z.norm(2, 1, keepdim=True)\n",
        "        z_normalization = torch.where(z_normalization == 0, torch.tensor(1.).to(z_normalization), z_normalization)\n",
        "        z = z / z_normalization\n",
        "\n",
        "        return z"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Similarity between Users & Movies\n",
        "\n",
        "Ref: https://docs.dgl.ai/en/0.6.x/guide/training-edge.html#guide-training-edge-classification"
      ],
      "metadata": {
        "id": "qf5aU6sFt2FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for NN Similarity"
      ],
      "metadata": {
        "id": "QEKN6jUAuVhL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOIrBbKE66MJ"
      },
      "source": [
        "class NnSimilarityPredictingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_layer_dim: int):\n",
        "        super(NnSimilarityPredictingLayer, self).__init__()\n",
        "        self.hidden_layer_1 = nn.Linear(2 * embedding_layer_dim, hidden_layer_1_output_dim)\n",
        "        self.hidden_layer_2 = nn.Linear(hidden_layer_1_output_dim, hidden_layer_2_output_dim)\n",
        "        self.output = nn.Linear(hidden_layer_2_output_dim, 1)\n",
        "        self.relu_layer = nn.ReLU()\n",
        "        self.sigmoid_layer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden_layer_1(x)\n",
        "        x = self.relu_layer(x)\n",
        "        x = self.hidden_layer_2(x)\n",
        "        x = self.relu_layer(x)\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid_layer(x)\n",
        "        return x\n",
        "\n",
        "class NnPredictingModule(nn.Module):\n",
        "    def __init__(self, predicting_layer, embed_dim: int):\n",
        "        super(NnPredictingModule, self).__init__()\n",
        "        self.layer_nn = NnSimilarityPredictingLayer(embed_dim)\n",
        "\n",
        "    def forward(self, graph, h ):\n",
        "        ratings_dict = {}\n",
        "        edge_types_list = ['user', 'movie']\n",
        "\n",
        "        for edge_type in graph.canonical_etypes:\n",
        "            if edge_type[0] in edge_types_list and edge_type[2] in edge_types_list:\n",
        "                u_type, _, v_type = edge_type\n",
        "                src_nid, dst_nid = graph.all_edges(etype=edge_type) \n",
        "                emb_heads = h[u_type][src_nid]\n",
        "                emb_tails = h[v_type][dst_nid]\n",
        "                cat_embed = torch.cat((emb_heads, emb_tails), 1)\n",
        "                ratings = self.layer_nn(cat_embed)\n",
        "                ratings_dict[edge_type] = torch.flatten(ratings)\n",
        "        \n",
        "        ratings_dict = {key: torch.unsqueeze(ratings_dict[key], 1) for key in ratings_dict.keys()}\n",
        "\n",
        "        return ratings_dict"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for Cosine Similarity"
      ],
      "metadata": {
        "id": "goUkXwQ3wYmb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYRyf5ji-DpP"
      },
      "source": [
        "class CosinePrediction(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "        with graph.local_scope():\n",
        "            for edge_type in graph.canonical_edge_types:\n",
        "                try:\n",
        "                    graph.nodes[edge_type[0]].data['norm_h'] = torch_nn_func.normalize(h[etype[0]], p=2, dim=-1)\n",
        "                    graph.nodes[edge_type[2]].data['norm_h'] = torch_nn_func.normalize(h[etype[2]], p=2, dim=-1)\n",
        "                    graph.apply_edges(fn.u_dot_v('norm_h', 'norm_h', 'cos'), etype=edge_type)\n",
        "                except ValueError:\n",
        "                   print(\"Cosine similarity fucntion is not correct!\")\n",
        "            ratings = graph.edge_data['cos']\n",
        "        return ratings"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for Dot-Product Similarity\n",
        "\n",
        "Refs:\n",
        "- https://docs.dgl.ai/en/0.6.x/guide/minibatch-link.html\n",
        "- https://issueexplorer.com/issue/dmlc/dgl/3447"
      ],
      "metadata": {
        "id": "Nket1fgyz7b0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vdpsUcABkp8"
      },
      "source": [
        "class DotProductPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "      \n",
        "      with graph.local_scope():\n",
        "        for edge_type in graph.canonical_edge_types:\n",
        "          try:\n",
        "            graph.n_data['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=edge_type)\n",
        "          except KeyError:\n",
        "            pass\n",
        "        ratings = graph.edge_data['score']\n",
        "\n",
        "      return ratings"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for PairWise Distance Similarity"
      ],
      "metadata": {
        "id": "f5eCXAl7RKzz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWtmvC9ptFOg"
      },
      "source": [
        "class PairWiseDistancePredictor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "\n",
        "        with graph.local_scope():\n",
        "            for edge_type in graph.canonical_edge_types:\n",
        "                try:\n",
        "                    graph.nodes[edge_type[0]].data['h'] = h[edge_type[0]]\n",
        "                    graph.nodes[edge_type[2]].data['h'] = h[edge_type[2]]\n",
        "                    graph.apply_edges(lambda edges: {'pwdist': nn.PairwiseDistance('h', 'h')}, etype=edge_type )\n",
        "                except KeyError:\n",
        "                    pass\n",
        "            ratings = graph.edge_data['pwdist']\n",
        "\n",
        "        return ratings"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN Model"
      ],
      "metadata": {
        "id": "ky4oPq-PQyRn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hqSDUQK_OWP"
      },
      "source": [
        "class GNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, g, n_layers: int, dim_dict, dropout, pred, aggregator_hetero, embedding_layer,):\n",
        "\n",
        "        super().__init__()\n",
        "        self.embedding_layer = embedding_layer\n",
        "\n",
        "        if embedding_layer:\n",
        "            self.user_embed = NodeEmbedding(dim_dict['user'], dim_dict['hidden'])\n",
        "            self.item_embed = NodeEmbedding(dim_dict['movie'], dim_dict['hidden'])\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # input layer\n",
        "        if not embedding_layer:\n",
        "            self.layers.append(\n",
        "                dglnn.HeteroGraphConv(\n",
        "                    {etype[1]: MessagePassing((dim_dict[etype[0]], dim_dict[etype[2]]), dim_dict['hidden'], dropout) for etype in g.canonical_etypes}, \n",
        "                    aggregate=aggregator_hetero)\n",
        "                    )\n",
        "\n",
        "        # hidden layers\n",
        "        for i in range(n_layers - 2):\n",
        "            self.layers.append(\n",
        "                dglnn.HeteroGraphConv(\n",
        "                    {etype[1]: MessagePassing((dim_dict['hidden'], dim_dict['hidden']), dim_dict['hidden'], dropout) for etype in g.canonical_etypes},\n",
        "                    aggregate=aggregator_hetero)\n",
        "                    )\n",
        "\n",
        "        # output layer\n",
        "        self.layers.append(\n",
        "            dglnn.HeteroGraphConv(\n",
        "                {etype[1]: MessagePassing((dim_dict['hidden'], dim_dict['hidden']), dim_dict['out'], dropout) for etype in g.canonical_etypes}, \n",
        "                aggregate=aggregator_hetero)\n",
        "                )\n",
        "\n",
        "        if pred == 'cos':\n",
        "            self.pred_fn = CosinePrediction()\n",
        "        elif pred == 'nn':\n",
        "            self.pred_fn = NnPredictingModule(NnSimilarityPredictingLayer, dim_dict['out'])\n",
        "        elif pred == 'dotprod':\n",
        "            self.pred_fn = DotProductPredictor()\n",
        "        elif pred == 'pw':\n",
        "            self.pred_fn = PairWiseDistancePredictor()\n",
        "        else:\n",
        "            raise KeyError('Prediction function does not exist')\n",
        "            sys.exit(1)\n",
        "\n",
        "    def get_repr(self, blocks, h):\n",
        "\n",
        "        for i in range(len(blocks)):         \n",
        "            layer = self.layers[i]\n",
        "            h = layer(blocks[i], h)\n",
        "          \n",
        "        return h\n",
        "\n",
        "    def forward(self, blocks, h, pos_g, neg_g, embedding_layer: bool=True, ):\n",
        "\n",
        "        if embedding_layer:\n",
        "            h['user'] = self.user_embed(h['user'])\n",
        "            h['movie'] = self.item_embed(h['movie'])\n",
        "\n",
        "        h = self.get_repr(blocks, h)\n",
        "        pos_score = self.pred_fn(pos_g, h)\n",
        "        neg_score = self.pred_fn(neg_g, h)\n",
        "\n",
        "        return h, pos_score, neg_score"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Results in output file"
      ],
      "metadata": {
        "id": "NxgfENcofcdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_txt(data_to_save, filepath, mode='a'):\n",
        "\n",
        "    with open(filepath, mode) as text_file:\n",
        "        text_file.write(data_to_save + '\\n')"
      ],
      "metadata": {
        "id": "dzQ2HpGUe6on"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max Margin Loss\n"
      ],
      "metadata": {
        "id": "DrYf_KZVIy8p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDB4RSsp_nRo"
      },
      "source": [
        "def max_margin_loss(pos_score, neg_score, delta, neg_sample_size, negative_mask, cuda, device):\n",
        "\n",
        "    all_scores = torch.empty(0)\n",
        "\n",
        "    if cuda:\n",
        "        all_scores = all_scores.to(device)\n",
        "\n",
        "    for etype in pos_score.keys():\n",
        "        neg_score_tensor = neg_score[etype]\n",
        "        pos_score_tensor = pos_score[etype]\n",
        "        neg_score_tensor = neg_score_tensor.reshape(-1, neg_sample_size)\n",
        "        \n",
        "        negative_mask_tensor = negative_mask[etype].reshape(-1, neg_sample_size)\n",
        "       \n",
        "        if cuda:\n",
        "            negative_mask_tensor = negative_mask_tensor.to(device)\n",
        "        scores = (delta- pos_score_tensor + neg_score_tensor-negative_mask_tensor).clamp(min=0)\n",
        "        \n",
        "        if etype == edge_types[0]:\n",
        "            all_scores = torch.cat((all_scores, scores), 0)\n",
        "\n",
        "    return torch.mean(all_scores)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Personalized Ranking Loss"
      ],
      "metadata": {
        "id": "mAmTZKQqI29d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XypRtiIHSoTz"
      },
      "source": [
        "def bpr_loss(pos_score, neg_score, delta, neg_sample_size, negative_mask, cuda, device):\n",
        "\n",
        "    all_scores = torch.empty(0)\n",
        "\n",
        "    if cuda:\n",
        "        all_scores = all_scores.to(device)\n",
        "\n",
        "    for etype in pos_score.keys():\n",
        "        neg_score_tensor = neg_score[etype]\n",
        "        pos_score_tensor = pos_score[etype]\n",
        "        neg_score_tensor = neg_score_tensor.reshape(-1, neg_sample_size)\n",
        "\n",
        "        negative_mask_tensor = negative_mask[etype].reshape(-1, neg_sample_size)\n",
        "        \n",
        "\n",
        "        if cuda:\n",
        "            negative_mask_tensor = negative_mask_tensor.to(device)\n",
        "\n",
        "        logsig = nn.LogSigmoid()\n",
        "        scores = - logsig(pos_score_tensor - neg_score_tensor - negative_mask_tensor)\n",
        "        \n",
        "        if etype == edge_types[0]: \n",
        "          all_scores = torch.cat((all_scores, scores), 0)\n",
        "\n",
        "    return torch.mean(all_scores)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Entropy Loss"
      ],
      "metadata": {
        "id": "Dc7CXglkI9Ev"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYV9IwcBp2CK"
      },
      "source": [
        "def cross_entropy_loss(positive_score, negative_score, delta, negative_sample_size , negative_mask, cuda, device):\n",
        "    \n",
        "    all_scores = torch.empty(0)\n",
        "    \n",
        "    if cuda:\n",
        "        all_scores = all_scores.to(device)\n",
        "    \n",
        "    for edge_type in positive_score.keys():\n",
        "        negative_score_tensor = negative_score[edge_type].reshape(-1, 1)\n",
        "        positive_score_tensor = positive_score[edge_type]\n",
        "    \n",
        "        negative_mask_tensor = negative_mask[edge_type].reshape(-1, 1)\n",
        "    \n",
        "        if cuda:\n",
        "            negative_mask_tensor = negative_mask_tensor.to(device)\n",
        "    \n",
        "        relu = nn.ReLU()\n",
        "\n",
        "        if edge_type == edge_types[0]:\n",
        "            all_scores = torch.cat((all_scores, positive_score_tensor), 0)\n",
        "            negative_score_tensor = negative_score_tensor - negative_mask_tensor\n",
        "            all_scores = torch.cat((all_scores, negative_score_tensor), 0).reshape(-1, 1)\n",
        "            all_scores = relu(all_scores)\n",
        "            labels = torch.cat([torch.ones(positive_score_tensor.shape[0]), torch.zeros(negative_score_tensor.shape[0])]).reshape(-1, 1)\n",
        "\n",
        "            if cuda:\n",
        "                all_scores = all_scores.to(device) \n",
        "                labels = labels.to(device)\n",
        "        \n",
        "    loss = torch_nn_func.binary_cross_entropy_with_logits(all_scores, labels)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling the Training Graph as well as Node/Edge IDs for training and validation"
      ],
      "metadata": {
        "id": "jZV6xHXjQH1D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szMr2FfT2qhF"
      },
      "source": [
        "def train_validation_split(valid_graph, ground_truth_test, etypes, valid_size, reverse_etype):\n",
        "    \n",
        "    np.random.seed(11)\n",
        "\n",
        "    all_eids_dict, valid_eids_dict, train_eids_dict = {}, {}, {}\n",
        "    valid_uids_all, valid_iids_all = [], []\n",
        "\n",
        "    for etype in etypes:\n",
        "      all_eids = np.arange(valid_graph.number_of_edges(etype))\n",
        "      all_eids_dict[etype] = all_eids\n",
        "      valid_eids = all_eids[int(len(all_eids) * (1 - valid_size)):]\n",
        "      valid_eids_dict[etype] = valid_eids\n",
        "    \n",
        "    all_eids_dict[etypes[0]] = all_eids\n",
        "    valid_eids = all_eids[int(len(all_eids) * (1 - valid_size)):]\n",
        "\n",
        "    valid_uids, valid_iids = valid_graph.find_edges(valid_eids, etype=etypes[0])\n",
        "    valid_uids_all.extend(valid_uids.tolist())\n",
        "    valid_iids_all.extend(valid_iids.tolist())\n",
        "        \n",
        "    ground_truth_valid = (np.array(valid_uids_all), np.array(valid_iids_all))\n",
        "    valid_uids = np.array(np.unique(valid_uids_all))\n",
        "\n",
        "    train_graph = valid_graph.clone()\n",
        "\n",
        "    for etype in etypes:\n",
        "      train_graph.remove_edges(valid_eids_dict[etype], etype=etype)\n",
        "      train_eids = np.arange(train_graph.number_of_edges(etype))\n",
        "      train_eids_dict[etype] = train_eids\n",
        "\n",
        "    validation_graph = valid_graph.clone()\n",
        "\n",
        "    for etype in etypes:\n",
        "      validation_graph.remove_edges(train_eids_dict[etype], etype=etype)\n",
        "\n",
        "    train_uids, train_iids =train_graph.find_edges(train_eids_dict[etypes[0]], etype=etypes[0])\n",
        "    unique_train_uids = np.unique(train_uids)\n",
        "\n",
        "    ground_truth_train = (np.array(train_uids), np.array(train_iids))\n",
        "    train_uids = np.array(np.unique(train_uids))\n",
        "    test_uids, _ = ground_truth_test\n",
        "    test_uids = np.unique(test_uids)\n",
        "    all_iids = np.arange(valid_graph.num_nodes('movie'))\n",
        "\n",
        "    return train_graph, train_eids_dict, valid_eids_dict, train_uids, valid_uids, test_uids, all_iids, ground_truth_train, ground_truth_valid, all_eids_dict"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling --> Creating batches for train, valid & test data\n",
        "Since data is large, it is fed to the model in batches. "
      ],
      "metadata": {
        "id": "y2RtL0Yy3oQX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r70EqCZtE8Eu"
      },
      "source": [
        "def load_data(validation_graph, train_graph, train_edge_ids_dict, validation_edge_ids_dict, train_u_ids, validation_u_ids, test_u_ids, all_i_ids, \n",
        "                          number_workers, embedding_layer, number_layers, neighbor_sampler, neg_sample_size,  edge_batch_size, \n",
        "                          node_batch_size):\n",
        "   \n",
        "    if embedding_layer:\n",
        "        number_layers -= 1\n",
        "    if neighbor_sampler == 'full':\n",
        "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(number_layers)\n",
        "    elif neighbor_sampler == 'partial':\n",
        "        sampler = dgl.dataloading.MultiLayerNeighborSampler(block_sampler, replace=False)\n",
        "    else:\n",
        "        print('Neighbor sampler does not exit')\n",
        "        sys.exit(1)\n",
        "\n",
        "    sampler_n = dgl.dataloading.negative_sampler.Uniform(neg_sample_size)\n",
        "\n",
        "    #loading nodes\n",
        "    nodeLoad_train = dgl.dataloading.NodeDataLoader(train_graph, {'user': train_u_ids, 'movie': all_i_ids}, sampler, batch_size=node_batch_size, shuffle=True, \n",
        "                                                      drop_last=False, num_workers=number_workers,)\n",
        "\n",
        "    nodeLoad_validation = dgl.dataloading.NodeDataLoader(validation_graph, {'user': validation_u_ids, 'movie': all_i_ids}, sampler, batch_size=node_batch_size, \n",
        "                                                           shuffle=True, drop_last=False, num_workers=number_workers,)\n",
        "\n",
        "    #loading edges\n",
        "\n",
        "    edgeLoad_train = dgl.dataloading.EdgeDataLoader(train_graph, train_edge_ids_dict, sampler, exclude='reverse_types', \n",
        "                                                          reverse_etypes={'buys': 'watched-by', 'watched-by': 'buys'}, negative_sampler=sampler_n, \n",
        "                                                          batch_size=edge_batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=number_workers,)\n",
        "\n",
        "    edgeLoad_validation = dgl.dataloading.EdgeDataLoader(validation_graph, validation_edge_ids_dict, sampler, g_sampling=train_graph, negative_sampler=sampler_n, \n",
        "                                                      batch_size=edge_batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=number_workers,)\n",
        "\n",
        "    \n",
        "    test_node_ids = {'user': test_u_ids, 'movie': all_i_ids}\n",
        "\n",
        "    nodeLoad_test = dgl.dataloading.NodeDataLoader(validation_graph, test_node_ids, sampler, batch_size=node_batch_size, shuffle=True, drop_last=False, \n",
        "                                                     num_workers=number_workers)\n",
        "\n",
        "    return edgeLoad_train, edgeLoad_validation, nodeLoad_train, nodeLoad_validation, nodeLoad_test\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9pRpEAsQ8Fi"
      },
      "source": [
        "## Design Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu-UGMfgOJpH"
      },
      "source": [
        "edge_types= [('user', 'buys', 'movie'), ('movie', 'watched-by', 'user')]\n",
        "reverse_edge_types= {('user', 'buys', 'movie'): ('movie', 'watched-by', 'user'), \n",
        "                 ('movie', 'watched-by', 'user') : ('user', 'buys', 'movie') }\n",
        "validation_size = .15\n",
        "cuda = torch.cuda.is_available()\n",
        "number_workers = 1 if cuda else 0\n",
        "device = torch.device('cuda') if cuda else torch.device('cpu')\n",
        "\n",
        "embedding_layer = True  \n",
        "number_layers = 3\n",
        "neighbor_sampler = 'partial' \n",
        "block_sampler = [50, 40 ]\n",
        "neg_sample_size = 15 \n",
        "edge_batch_size = 4096 \n",
        "node_batch_size = 128\n",
        "\n",
        "# GNN Conv Layer parameters:\n",
        "out_dim = 64 \n",
        "hidden_dim = 256\n",
        "validation_graph = hetero_graph\n",
        "prediction = 'nn' \n",
        "aggregator_hetero = 'mean' \n",
        "dropout = 0.3 \n",
        "\n",
        "# nn PredLayer parameters:\n",
        "hidden_layer_1_output_dim = 256 \n",
        "hidden_layer_2_output_dim = 128 \n",
        "\n",
        "num_epochs = 15 \n",
        "delta = 0.6 \n",
        "\n",
        "optimizer=torch.optim.Adam \n",
        "lr = 0.001 \n",
        "weight_decay = 1e-5\n",
        "loss_function = bpr_loss \n",
        "patience = 20\n",
        "result_filepath = '/content/drive/My Drive/DL-PROJECT/output.txt'\n",
        "k = 5 #number of recommendations\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzP-qUyrQ_t3"
      },
      "source": [
        "## Initialize Dataloaders - Get Training & Test IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBYotwno0CYE"
      },
      "source": [
        "train_graph, train_edge_ids_dict, validation_edge_ids_dict, train_u_ids, validation_u_ids, test_u_ids, all_i_ids, ground_truth_train, ground_truth_validation, all_edge_ids_dict = train_validation_split(hetero_graph, ground_truth_test, edge_types, \n",
        "                                                                                                                                                                      validation_size, reverse_edge_types)\n",
        "\n",
        "edgeLoad_train, edgeLoad_validation, nodeLoad_train, nodeLaod_validation, nodeLoad_test = load_data(validation_graph, train_graph, train_edge_ids_dict, \n",
        "                                                                                                                      validation_edge_ids_dict, train_u_ids, validation_u_ids, \n",
        "                                                                                                                      test_u_ids, all_i_ids, number_workers,  \n",
        "                                                                                                                      embedding_layer, number_layers, neighbor_sampler, \n",
        "                                                                                                                      neg_sample_size, \n",
        "                                                                                                                      edge_batch_size, node_batch_size)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Number of Batches for Train, Validation and Test Data"
      ],
      "metadata": {
        "id": "NQ3hD-cfLJ3T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxHjKucALmUA"
      },
      "source": [
        "train_edge_ids_len = 0\n",
        "validation_edge_ids_len = 0\n",
        "\n",
        "for edge_type in train_edge_ids_dict.keys():\n",
        "    train_edge_ids_len += len(train_edge_ids_dict[edge_type])\n",
        "    validation_edge_ids_len += len(validation_edge_ids_dict[edge_type])\n",
        "\n",
        "num_batches_train_loss = math.ceil(train_edge_ids_len / edge_batch_size)\n",
        "num_batches_train_metrics = math.ceil((len(train_u_ids) + len(all_i_ids)) / node_batch_size)\n",
        "num_batches_validation_loss = math.ceil(validation_edge_ids_len /edge_batch_size)\n",
        "num_batches_validation_metrics = math.ceil((len(validation_u_ids) + len(all_i_ids)) / node_batch_size)\n",
        "num_batches_test = math.ceil((len(test_u_ids) + len(all_i_ids)) / node_batch_size)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Embeddings"
      ],
      "metadata": {
        "id": "HOY-D9J3kibM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdyq5Y3jbZ4M"
      },
      "source": [
        "def get_embeddings(g, out_dim, trained_model, nodeLoad_test, num_batches_valid, cuda, device, embedding_layer):\n",
        "\n",
        "    if cuda:  \n",
        "        trained_model = trained_model.to(device)\n",
        "    i = 0\n",
        "    y = {ntype: torch.zeros(g.num_nodes(ntype), out_dim) for ntype in g.ntypes}\n",
        "    \n",
        "    if cuda: \n",
        "        y = {ntype: torch.zeros(g.num_nodes(ntype), out_dim).to(device) for ntype in g.ntypes}\n",
        "    \n",
        "    for input_nodes, output_nodes, blocks in nodeLoad_test:\n",
        "        i += 1\n",
        "       \n",
        "        if i % 10 == 0:\n",
        "            print(\"Computing embeddings: Batch \"+ str(i)+ \" out of \"  + str(num_batches_valid))\n",
        "       \n",
        "        if cuda:\n",
        "            blocks = [b.to(device) for b in blocks]\n",
        "        \n",
        "        input_features = blocks[0].srcdata['features']\n",
        "\n",
        "        if embedding_layer:\n",
        "            input_features['user'] = trained_model.user_embed(input_features['user'])\n",
        "            input_features['movie'] = trained_model.item_embed(input_features['movie'])\n",
        "        \n",
        "        h = trained_model.get_repr(blocks, input_features)\n",
        "        \n",
        "        for ntype in h.keys():\n",
        "            y[ntype][output_nodes[ntype]] = h[ntype]\n",
        "\n",
        "    return y"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Metrics "
      ],
      "metadata": {
        "id": "FVzz6pcykmVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(h, g, model, embed_dim, ground_truth, k, cuda=False, device=None, pred='cos', epoch=4):\n",
        "\n",
        "    users, items = ground_truth\n",
        "    user_ids = np.unique(users).tolist()\n",
        "    ground_truth_arr = np.stack((np.asarray(users), np.asarray(items)), axis=1)\n",
        "    ground_truth_dict = defaultdict(list)\n",
        "    for key, val in ground_truth_arr:\n",
        "        ground_truth_dict[key].append(val)\n",
        "    recs = get_recom(g, h, model, embed_dim, k, user_ids, cuda, device, pred, epoch)\n",
        "    precision, coverage = calculate_metrics(recs, ground_truth_dict, g)\n",
        "    \n",
        "    return precision, coverage"
      ],
      "metadata": {
        "id": "klY0TTgFLbWA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Recommendations"
      ],
      "metadata": {
        "id": "zqP_FYcRksdJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htK3x_2WcDH_"
      },
      "source": [
        "def calculate_metrics(recs, ground_truth_dict, g):\n",
        "\n",
        "    k_relevant = 0\n",
        "    k_total = 0\n",
        "\n",
        "    for uid, iids in recs.items():\n",
        "        k_total += len(iids)\n",
        "        k_relevant += len([id_ for id_ in iids if id_ in ground_truth_dict[uid]])\n",
        "    \n",
        "    precision = k_relevant/k_total\n",
        "\n",
        "    nb_total = g.num_nodes('movie')\n",
        "    recs_flatten = [item for sublist in list(recs.values()) for item in sublist]\n",
        "    nb_recommended = len(set(recs_flatten))\n",
        "    coverage = nb_recommended / nb_total\n",
        "    \n",
        "    return precision, coverage\n",
        "  \n",
        "def get_recom(g, h, model, embed_dim, k, user_ids, cuda, device, pred: str, epoch):\n",
        "\n",
        "    if cuda:  \n",
        "        model = model.to(device)\n",
        "\n",
        "    recom = {}\n",
        "\n",
        "    for user in user_ids:\n",
        "        user_emb = h['user'][user]\n",
        "        user_emb_rpt = torch.cat(g.num_nodes('movie') * [user_emb]).reshape(-1, embed_dim) \n",
        "        \n",
        "        if pred == 'cos':\n",
        "            cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "            ratings = cos(user_emb_rpt, h['movie'])\n",
        "        elif pred == 'nn':\n",
        "            cat_embed = torch.cat((user_emb_rpt, h['movie']), 1)\n",
        "            ratings = model.pred_fn.layer_nn(cat_embed)\n",
        "        elif pred == 'dotprod':\n",
        "            ratings = torch.sum(user_emb_rpt * h['movie'], dim=1)\n",
        "            print(\"ratings shape: \", ratings.shape)\n",
        "        elif pred == 'pw':\n",
        "            ratings =nn.PairwiseDistance(user_emb_rpt, h['movie'])\n",
        "        else:\n",
        "            print ('the prediction function not found!')\n",
        "            sys.exit(1)\n",
        "            \n",
        "        ratings_formatted = ratings.cpu().detach().numpy().reshape(g.num_nodes('movie'),)\n",
        "        order = np.argsort(-ratings_formatted)\n",
        "\n",
        "        rec = order[:k] # top k recommendations\n",
        "        recom[user] = rec\n",
        "        \n",
        "    return recom\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate AUC"
      ],
      "metadata": {
        "id": "P_JKy3sfLsJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_auc(scores):\n",
        "    edge_type = ('user', 'buys', 'movie')\n",
        "    pos_score = scores[0][edge_type]\n",
        "    neg_score = scores[1][edge_type]\n",
        "\n",
        "    scores = torch.cat([pos_score, neg_score]).detach().cpu().numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).detach().numpy()\n",
        "\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "cp41jia9Ln_1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "iR2p1Ys4Yvw6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlixm7hFSsbk"
      },
      "source": [
        "def train_model(model,\n",
        "                num_epochs,\n",
        "                num_batches_train_loss,\n",
        "                num_batches_validation_loss,\n",
        "                num_batches_val_metrics,\n",
        "                num_batches_train_metric,\n",
        "                edgeLoad_train,\n",
        "                edgeLoad_validation,\n",
        "                nodeLoad_validation,\n",
        "                nodeLoad_train,\n",
        "                k,\n",
        "                loss_function, \n",
        "                delta, \n",
        "                negative_sample_size, \n",
        "                cuda=False,\n",
        "                device=None,\n",
        "                optimizer=torch.optim.Adam,\n",
        "                lr=0.001,\n",
        "                train_graph=None,\n",
        "                validation_graph=None,\n",
        "                out_dim=None,\n",
        "                ground_truth_train=None,\n",
        "                ground_truth_validation=None,\n",
        "                result_filepath=None,\n",
        "                patience=5,\n",
        "                prediction=None,\n",
        "                embedding_layer=True,\n",
        "                ):\n",
        "\n",
        "    model.train_loss_list, model.train_precision_list, model.train_coverage_list, model.validation_loss_list, model.validation_precision_list, model.validation_coverage_list = [], [], [], [], [], []\n",
        "    best_metrics = {} \n",
        "    \n",
        "    max_metric = - 0.1\n",
        "    patience_counter = 0  \n",
        "    min_loss = 1.1\n",
        "\n",
        "    opt = optimizer(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    start = time.time()\n",
        "    print('Start training for '+ str(num_epochs)+ ' epochs')\n",
        "    \n",
        "    for epoch in range(1, num_epochs):\n",
        "        \n",
        "        if epoch == 1:\n",
        "            mode = 'w'  \n",
        "        else:\n",
        "            mode = 'a'  \n",
        "\n",
        "        model.train()  \n",
        "        i = 0\n",
        "        total_loss = 0\n",
        "        for _, pos_g, neg_g, blocks in edgeLoad_train:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Negative mask\n",
        "            negative_mask = {}\n",
        "\n",
        "            nids = neg_g.ndata[dgl.NID]\n",
        "\n",
        "            for etype in pos_g.canonical_etypes:\n",
        "                neg_src, neg_dst = neg_g.edges(etype=etype)\n",
        "                neg_src = nids[etype[0]][neg_src]\n",
        "                neg_dst = nids[etype[2]][neg_dst]\n",
        "                negative_mask_tensor = train_graph.has_edges_between(neg_src, neg_dst, etype=etype)\n",
        "                negative_mask[etype] = negative_mask_tensor.type(torch.float)\n",
        "\n",
        "                if cuda:\n",
        "                    negative_mask[etype] = negative_mask[etype].to(device)\n",
        "\n",
        "            if cuda:\n",
        "                blocks = [b.to(device) for b in blocks]\n",
        "                pos_g = pos_g.to(device)\n",
        "                neg_g = neg_g.to(device)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(\"Edge batch \" + str(i) + \" out of \", str(num_batches_train_loss))\n",
        "\n",
        "            input_features = blocks[0].srcdata['features']\n",
        "\n",
        "            _, pos_score, neg_score = model(blocks, input_features, pos_g, neg_g, embedding_layer,)\n",
        "            train_score = (pos_score, neg_score)\n",
        "            loss = loss_function(pos_score, neg_score, delta, neg_sample_size, negative_mask=negative_mask, cuda=cuda, device=device,)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_avg_loss = total_loss / i\n",
        "        model.train_loss_list.append(train_avg_loss)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            i = 0\n",
        "\n",
        "            for _, pos_g, neg_g, blocks in edgeLoad_validation:\n",
        "                i += 1\n",
        "\n",
        "                if i % 10 == 0:\n",
        "                    print(\"Edge batch {} out of {}\".format(i, num_batches_validation_loss))\n",
        "\n",
        "                # Negative mask\n",
        "                negative_mask = {}\n",
        "\n",
        "                nids = neg_g.ndata[dgl.NID]\n",
        "\n",
        "                for etype in pos_g.canonical_etypes:\n",
        "                    neg_src, neg_dst = neg_g.edges(etype=etype)\n",
        "                    neg_src = nids[etype[0]][neg_src]\n",
        "                    neg_dst = nids[etype[2]][neg_dst]\n",
        "                    negative_mask_tensor = validation_graph.has_edges_between(neg_src, neg_dst, etype=etype)\n",
        "                    negative_mask[etype] = negative_mask_tensor.type(torch.float)\n",
        "\n",
        "                    if cuda:\n",
        "                        negative_mask[etype] = negative_mask[etype].to(device)\n",
        "\n",
        "                if cuda:\n",
        "                    blocks = [b.to(device) for b in blocks]\n",
        "                    pos_g = pos_g.to(device)\n",
        "                    neg_g = neg_g.to(device)\n",
        "\n",
        "                input_features = blocks[0].srcdata['features']\n",
        "                _, pos_score, neg_score = model(blocks, input_features, pos_g, neg_g, embedding_layer,)\n",
        "                \n",
        "                validation_score = (pos_score, neg_score)\n",
        "\n",
        "                validation_loss = loss_function(pos_score, neg_score, delta, neg_sample_size, negative_mask=negative_mask, \n",
        "                                   cuda=cuda, device=device,)\n",
        "                total_loss += validation_loss.item()\n",
        "\n",
        "            validation_avg_loss = total_loss / i\n",
        "            model.validation_loss_list.append(validation_avg_loss)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y = get_embeddings(train_graph, out_dim, model, nodeLoad_train, num_batches_train_metrics, cuda, device, embedding_layer,)\n",
        "            train_precision, train_coverage = get_metrics(y, train_graph, model, out_dim, ground_truth_train, k, \n",
        "                                                                cuda, device, prediction, epoch)\n",
        "\n",
        "            # validation metrics\n",
        "            y = get_embeddings(validation_graph,\n",
        "                                out_dim,\n",
        "                                model,\n",
        "                                nodeLoad_validation,\n",
        "                                num_batches_val_metrics,\n",
        "                                cuda,\n",
        "                                device,\n",
        "                                embedding_layer,\n",
        "                                )\n",
        "\n",
        "            validation_precision, validation_coverage = get_metrics(y, validation_graph, model, out_dim, ground_truth_validation,  k, \n",
        "                                                                          cuda, device, prediction, epoch)\n",
        "            AUC_val = compute_auc(validation_score)\n",
        "            AUC_train = compute_auc(train_score)\n",
        "            results = \"Epoch \" + str(epoch) +\" | Training loss \" + str(round(train_avg_loss,4)) +\" | Training Precision \" + str(round(train_precision * 100,2)) + \" | Training AUC \" + str(round(AUC_train,2))+ ' | Validation loss '+ str(round(validation_avg_loss,4)) + ' | Validation Precision '+str(round(validation_precision * 100,2)) + ' | AUC '+str(round(AUC_val,2))\n",
        "          \n",
        "            \n",
        "            print(results)\n",
        "            print('process time: ' +str(round(float(time.time()-start)/60, 2))+ ' minutes')\n",
        "            \n",
        "            save_txt(results, result_filepath, mode=mode)\n",
        "\n",
        "            model.train_precision_list.append(train_precision * 100)\n",
        "            model.validation_precision_list.append(validation_precision * 100)\n",
        "\n",
        "            if validation_precision > max_metric:\n",
        "                max_metric = validation_precision\n",
        "                best_metrics = { 'precision': validation_precision}\n",
        "\n",
        "       \n",
        "        if validation_avg_loss < min_loss:\n",
        "            min_loss = validation_avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter == patience:\n",
        "            break\n",
        "\n",
        "    viz_dict = {'train_loss_list': model.train_loss_list,\n",
        "           'train_precision_list': model.train_precision_list,\n",
        "           'val_loss_list': model.validation_loss_list,\n",
        "           'validation_precision_list': model.validation_precision_list,\n",
        "          }\n",
        "    \n",
        "    print('end of training!!')\n",
        "    print ('process time: ' +str(round(float(time.time()-start)/60, 2))+ ' minutes')\n",
        "    return model, viz_dict, validation_score, train_score, best_metrics"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_hN-1ZlY7ztv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference\n",
        "### Apply the Trained Model to the Test Data"
      ],
      "metadata": {
        "id": "kkX0DN5_dgQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def model_inference(valid_graph, out_dim: int, trained_model, nodeLoad_test, num_batches_test: int, cuda: bool, device, embedding_layer: bool, \n",
        "                     ground_truth_test, all_eids_dict):\n",
        "\n",
        "    trained_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "          embeddings = get_embeddings(valid_graph, out_dim, trained_model, nodeLoad_test, num_batches_test, cuda, device, embedding_layer,)\n",
        "          precision,_ = get_metrics(embeddings, valid_graph, trained_model, out_dim, ground_truth_test, k, cuda, device, prediction, epoch = 4)\n",
        "          sentence = \" TEST Precision {:.3f}% \".format(precision * 100)\n",
        "          print(sentence)\n",
        "          save_txt(sentence, result_filepath, mode= 'a')"
      ],
      "metadata": {
        "id": "KpZGcVQlNX8P"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Main Script to Run and Train the Model"
      ],
      "metadata": {
        "id": "F5SAkqllcJuZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2FHOQjm9-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2b0c08-c055-4cc7-d115-6c2b0f6024be"
      },
      "source": [
        "\n",
        "dim_dict = {'user': validation_graph.nodes['user'].data['features'].shape[1],\n",
        "            'movie': validation_graph.nodes['movie'].data['features'].shape[1],\n",
        "            'out': out_dim,\n",
        "            'hidden': hidden_dim}\n",
        "\n",
        "model = GNNModel(validation_graph, number_layers, dim_dict, dropout, prediction, aggregator_hetero, embedding_layer)\n",
        "\n",
        "if cuda:\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "trained_model, viz_dict, validation_score, train_score, best_metrics = train_model(model, \n",
        "                                                                       num_epochs,                                                      \n",
        "                                                                        num_batches_train_loss, \n",
        "                                                                        num_batches_validation_loss,\n",
        "                                                                        num_batches_validation_metrics,\n",
        "                                                                        num_batches_train_metrics, \n",
        "                                                                        edgeLoad_train, \n",
        "                                                                        edgeLoad_validation,\n",
        "                                                                        nodeLaod_validation, \n",
        "                                                                        nodeLoad_train, \n",
        "                                                                        k,\n",
        "                                                                        loss_function, \n",
        "                                                                        delta, \n",
        "                                                                        neg_sample_size,\n",
        "                                                                        cuda,\n",
        "                                                                        device,\n",
        "                                                                        optimizer,\n",
        "                                                                        lr,\n",
        "                                                                        train_graph, \n",
        "                                                                        validation_graph,\n",
        "                                                                        out_dim, \n",
        "                                                                        ground_truth_train, \n",
        "                                                                        ground_truth_validation, \n",
        "                                                                        result_filepath,\n",
        "                                                                        patience,\n",
        "                                                                        prediction,\n",
        "                                                                        embedding_layer\n",
        "                                                                      )\n",
        "\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 15 epochs\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 1 | Training loss 0.6494 | Training Precision 14.83 | Training AUC 0.73 | Validation loss 0.6479 | Validation Precision 23.67 | AUC 0.73\n",
            "process time: 1.5 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 2 | Training loss 0.6164 | Training Precision 18.81 | Training AUC 0.77 | Validation loss 0.63 | Validation Precision 16.69 | AUC 0.74\n",
            "process time: 3.0 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 3 | Training loss 0.6036 | Training Precision 14.3 | Training AUC 0.78 | Validation loss 0.632 | Validation Precision 11.51 | AUC 0.73\n",
            "process time: 4.49 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 4 | Training loss 0.5993 | Training Precision 18.48 | Training AUC 0.79 | Validation loss 0.6271 | Validation Precision 14.87 | AUC 0.74\n",
            "process time: 5.99 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 5 | Training loss 0.5945 | Training Precision 18.3 | Training AUC 0.79 | Validation loss 0.6261 | Validation Precision 18.91 | AUC 0.75\n",
            "process time: 7.49 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 6 | Training loss 0.5917 | Training Precision 31.02 | Training AUC 0.79 | Validation loss 0.6264 | Validation Precision 23.78 | AUC 0.75\n",
            "process time: 8.98 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 7 | Training loss 0.5872 | Training Precision 30.8 | Training AUC 0.81 | Validation loss 0.6291 | Validation Precision 24.2 | AUC 0.74\n",
            "process time: 10.48 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 8 | Training loss 0.5809 | Training Precision 30.26 | Training AUC 0.81 | Validation loss 0.6197 | Validation Precision 23.53 | AUC 0.77\n",
            "process time: 11.98 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 9 | Training loss 0.5794 | Training Precision 27.14 | Training AUC 0.82 | Validation loss 0.6183 | Validation Precision 23.89 | AUC 0.75\n",
            "process time: 13.48 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 10 | Training loss 0.5776 | Training Precision 37.73 | Training AUC 0.82 | Validation loss 0.6177 | Validation Precision 28.73 | AUC 0.75\n",
            "process time: 14.99 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 11 | Training loss 0.5762 | Training Precision 34.73 | Training AUC 0.82 | Validation loss 0.6222 | Validation Precision 24.93 | AUC 0.75\n",
            "process time: 16.48 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 12 | Training loss 0.5741 | Training Precision 40.38 | Training AUC 0.82 | Validation loss 0.6191 | Validation Precision 27.82 | AUC 0.76\n",
            "process time: 17.98 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 13 | Training loss 0.5719 | Training Precision 33.9 | Training AUC 0.82 | Validation loss 0.6279 | Validation Precision 28.16 | AUC 0.74\n",
            "process time: 19.45 minutes\n",
            "Edge batch 10 out of  299\n",
            "Edge batch 20 out of  299\n",
            "Edge batch 30 out of  299\n",
            "Edge batch 40 out of  299\n",
            "Edge batch 50 out of  299\n",
            "Edge batch 60 out of  299\n",
            "Edge batch 70 out of  299\n",
            "Edge batch 80 out of  299\n",
            "Edge batch 90 out of  299\n",
            "Edge batch 100 out of  299\n",
            "Edge batch 110 out of  299\n",
            "Edge batch 120 out of  299\n",
            "Edge batch 130 out of  299\n",
            "Edge batch 140 out of  299\n",
            "Edge batch 150 out of  299\n",
            "Edge batch 160 out of  299\n",
            "Edge batch 170 out of  299\n",
            "Edge batch 180 out of  299\n",
            "Edge batch 190 out of  299\n",
            "Edge batch 200 out of  299\n",
            "Edge batch 210 out of  299\n",
            "Edge batch 220 out of  299\n",
            "Edge batch 230 out of  299\n",
            "Edge batch 240 out of  299\n",
            "Edge batch 250 out of  299\n",
            "Edge batch 260 out of  299\n",
            "Edge batch 270 out of  299\n",
            "Edge batch 280 out of  299\n",
            "Edge batch 290 out of  299\n",
            "Edge batch 10 out of 53\n",
            "Edge batch 20 out of 53\n",
            "Edge batch 30 out of 53\n",
            "Edge batch 40 out of 53\n",
            "Edge batch 50 out of 53\n",
            "Computing embeddings: Batch 10 out of 62\n",
            "Computing embeddings: Batch 20 out of 62\n",
            "Computing embeddings: Batch 30 out of 62\n",
            "Computing embeddings: Batch 40 out of 62\n",
            "Computing embeddings: Batch 50 out of 62\n",
            "Computing embeddings: Batch 60 out of 62\n",
            "Computing embeddings: Batch 10 out of 36\n",
            "Computing embeddings: Batch 20 out of 36\n",
            "Computing embeddings: Batch 30 out of 36\n",
            "Epoch 14 | Training loss 0.5713 | Training Precision 32.95 | Training AUC 0.81 | Validation loss 0.6275 | Validation Precision 27.13 | AUC 0.74\n",
            "process time: 20.93 minutes\n",
            "end of training!!\n",
            "process time: 20.93 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply the Trained Model on Test Data"
      ],
      "metadata": {
        "id": "xL2fIFYoX1D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inference(validation_graph, out_dim, trained_model, nodeLoad_test, num_batches_test, cuda, device, embedding_layer, ground_truth_test, all_edge_ids_dict)"
      ],
      "metadata": {
        "id": "-nwAkENTXyiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edafed1-2661-421f-ea41-21f4beaea27b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing embeddings: Batch 10 out of 38\n",
            "Computing embeddings: Batch 20 out of 38\n",
            "Computing embeddings: Batch 30 out of 38\n",
            " TEST Precision 11.725% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loV9z38qT8Jx"
      },
      "source": [
        "fig = plt.figure()\n",
        "x = list(range(1,len(viz_dict['train_loss_list'])+1))\n",
        "plt.title('\\n'.join(textwrap.wrap('train and validation loss', 60)))\n",
        "fig.tight_layout()\n",
        "plt.rcParams[\"axes.titlesize\"] = 6\n",
        "plt.plot(x, viz_dict['train_loss_list'])\n",
        "plt.plot(x, viz_dict['val_loss_list'])\n",
        "plt.legend(['training loss', 'valid loss'], loc='upper left')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('/content/drive/My Drive/DL-PROJECT/' + str(datetime.now())[:-10] + 'loss.png')\n",
        "plt.close(fig)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "x = list(range(1,len(viz_dict['train_precision_list'])+1))\n",
        "\n",
        "plt.title('\\n'.join(textwrap.wrap('train and validation precision', 60)))\n",
        "fig.tight_layout()\n",
        "plt.rcParams[\"axes.titlesize\"] = 6\n",
        "plt.plot(x, viz_dict['train_precision_list'])\n",
        "plt.plot(x, viz_dict['validation_precision_list'])\n",
        "plt.legend(['training precision','valid precision'], loc='upper left')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Percentage of metrics(%)')\n",
        "plt.savefig('/content/drive/My Drive/DL-PROJECT/' + str(datetime.now())[:-10] + 'metrics.png')\n",
        "plt.close(fig)"
      ],
      "execution_count": 79,
      "outputs": []
    }
  ]
}